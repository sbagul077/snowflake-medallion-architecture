{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "xv2wsgk4b3twiuwinnes",
   "authorId": "6625717515370",
   "authorName": "SANKET",
   "authorEmail": "",
   "sessionId": "25cb9430-8797-499e-9994-8516bf680fda",
   "lastEditTime": 1767680687898
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "9a23dc4f-84a8-45a8-966d-2c3345816976",
   "metadata": {
    "language": "sql",
    "name": "cell23"
   },
   "outputs": [],
   "source": "create or replace DATABASE CCDA_FINAL_ASSIGNMENT;\nUSE DATABASE CCDA_FINAL_ASSIGNMENT;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5673c980-ea6e-4baf-8b97-50fe05eed243",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "create or replace schema CCDA_FINAL_ASSIGNMENT.CCDA;\nUSE SCHEMA   CCDA_FINAL_ASSIGNMENT.CCDA;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a07af54-a23b-4722-b47f-06d16da0a419",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "DESC integration S3_STORAGE_INTEGRATION;\n\n--STORAGE_AWS_IAM_USER_ARN arn:aws:iam::053442322070:user/riee1000-s\n--STORAGE_AWS_EXTERNAL_ID  XXC67424_SFCRole=6_sBbq3/6qfjlLqEzGx3tBav9VsRU=\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a76df58c-1fec-427e-b430-4569098d4a5c",
   "metadata": {
    "name": "cell36",
    "collapsed": false
   },
   "source": ""
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "-- -- Create Snowflake Stage pointing at S3 XMLs\n\nCREATE OR REPLACE STAGE CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_XML_STAGE \n    URL = 's3://da-batch2-group1-capstone/CCDA_FILES/'\n    STORAGE_INTEGRATION = S3_STORAGE_INTEGRATION; ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "db731c83-d190-41e2-88a3-583e99398602",
   "metadata": {
    "language": "sql",
    "name": "cell26"
   },
   "outputs": [],
   "source": "LIST @CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_XML_STAGE",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7ca22eb-e045-4235-955d-82dbd727789f",
   "metadata": {
    "language": "sql",
    "name": "cell25"
   },
   "outputs": [],
   "source": "\n-- Create a named file format for XML\nCREATE OR REPLACE FILE FORMAT CCDA_FINAL_ASSIGNMENT.CCDA.FF_XML\n  TYPE = XML\n  DISABLE_AUTO_CONVERT = TRUE;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "620ed379-2874-4688-85f9-841874e09ea4",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": "\nCREATE OR REPLACE NOTIFICATION INTEGRATION S3_CCDA_EVENT\n  TYPE = QUEUE\n  DIRECTION = 'OUTBOUND'\n  ENABLED = TRUE\n  NOTIFICATION_PROVIDER = 'AWS_SNS'\n  AWS_SNS_TOPIC_ARN = 'arn:aws:sns:us-east-1:518729167346:SANKET_BAGUL_CCDA_S3_SNS'\n  AWS_SNS_ROLE_ARN = 'arn:aws:iam::518729167346:role/da-batch2-group1-role';\n  \n-- DESC S3_CCDA_EVENT;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86225126-171b-4377-90de-8485ef2877ff",
   "metadata": {
    "language": "sql",
    "name": "cell18"
   },
   "outputs": [],
   "source": "DESC INTEGRATION S3_CCDA_EVENT;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "964d1c83-7853-46c9-bfb7-00d96781e02f",
   "metadata": {
    "language": "sql",
    "name": "cell30"
   },
   "outputs": [],
   "source": "\nCREATE OR REPLACE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE (\n  FILE_NAME        STRING,\n  DOC              VARIANT,              -- parsed XML as VARIANT\n  LOAD_TS          TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n\n  -- Parser-enriched patient/document context\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,              -- JSON array of header IDs\n\n  -- Optional lineage\n  SOURCE_SYSTEM    STRING,               -- e.g., 'CCDA'\n  RECORD_TYPE      STRING                -- e.g., 'medications', 'allergies', etc. (if you fan-out directly)\n);\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91b02e4a-88fe-4529-b999-396f0fd318ad",
   "metadata": {
    "language": "sql",
    "name": "cell27"
   },
   "outputs": [],
   "source": "-- Link Integration to Snowpipe\n-- A native Bronze table for CCDA XML\nCREATE OR REPLACE TABLE CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE (\n  FILE_NAME STRING,\n  DOC       VARIANT,            -- parsed XML as VARIANT\n  LOAD_TS   TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n);\n\n\n-- CREATE OR REPLACE PIPE FINAL_ASSIGNMENT.CCDA.CCDA_pipe\n--   AUTO_INGEST = TRUE\n-- AS\nCOPY INTO CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE (FILE_NAME, DOC)\nFROM (\n  SELECT METADATA$FILENAME, PARSE_XML($1)            \n  FROM @CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_XML_STAGE\n  ( FILE_FORMAT => CCDA_FINAL_ASSIGNMENT.CCDA.FF_XML, PATTERN => '.*\\.xml' )\n)\nON_ERROR = 'CONTINUE';\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b1db0da-88be-44b9-b3e5-700ef2a73480",
   "metadata": {
    "language": "sql",
    "name": "cell28"
   },
   "outputs": [],
   "source": "DESC PIPE CCDA_FINAL_ASSIGNMENT.ccda.CCDA_PIPE; \n\n-- notification channel: arn:aws:sqs:us-east-1:846206542736:sf-snowpipe-AIDA4KBOXEOICMEARAYA4-PvSmKWm7xdr_3SGlGj-zsg\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "441c3bc0-7ba7-4459-970d-9b7cd9acd95f",
   "metadata": {
    "language": "sql",
    "name": "cell29"
   },
   "outputs": [],
   "source": "-- USE SCHEMA   FINAL_ASSIGNMENT.PUBLIC;\n-- Check pipes\n-- SHOW PIPES;\n\n\n-- -- View recent load history\n-- SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(\n--   table_name => 'CCDA_BRONZE',\n--   start_time => DATEADD('hour', -24, CURRENT_TIMESTAMP())\n-- ));\n\n-- Check notifications ingestion status\nSELECT SYSTEM$PIPE_STATUS('CCDA_pipe');\n\n-- -- Manually force a re-check (rarely needed)\n-- ALTER PIPE FINAL_ASSIGNMENT.PUBLIC.CCDA_PIPE REFRESH;\n\n\n-- SELECT * FROM TABLE(INFORMATION_SCHEMA.PIPE_USAGE_HISTORY(\n--     PIPE_NAME => 'FINAL_ASSIGNMENT.PUBLIC.CCDA_PIPE',\n--     START_TIME => DATEADD('hour', -1, CURRENT_TIMESTAMP())\n-- ));\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71e7b1ba-9ffd-41ba-b1b8-375b7f56cca6",
   "metadata": {
    "language": "sql",
    "name": "cell24"
   },
   "outputs": [],
   "source": "SELECT * FROM CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE;\n-- 1) Do we have any rows at all?\n-- SELECT COUNT(*) AS bronze_rows FROM FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE;\n-- \n-- -- 2) What does FILE_NAME look like in Bronze?\n-- SELECT DISTINCT FILE_NAME FROM FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE ORDER BY 1 LIMIT 50;\n\n-- -- 3) Does our hardcoded file exist (try fuzzy)?\n-- SELECT FILE_NAME\n-- FROM CCDA_BRONZE\n-- -- WHERE FILE_NAME ILIKE '%McGlynn426%'  -- adjust token\n-- LIMIT 20;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9dc4cd50-2dd4-4d46-bef9-59942b58852c",
   "metadata": {
    "language": "sql",
    "name": "cell22"
   },
   "outputs": [],
   "source": "\nCREATE OR REPLACE STREAM FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE_STREAM\n  ON TABLE FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE\n  APPEND_ONLY = TRUE;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "621715f5-9963-424e-a9f0-8c615008c9e7",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": "--Create Silver Schema & Tables (Snowflake)\n\nUSE DATABASE CCDA_FINAL_ASSIGNMENT;\nUSE SCHEMA CCDA_FINAL_ASSIGNMENT.CCDA;\n\n\nCREATE OR REPLACE TABLE CCDA_MEDICATIONS (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  STOP_RAW     STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  STOP_ISO     TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\nCREATE OR REPLACE TABLE CCDA_VITALS (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n  VALUE        STRING,\n  UNIT         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\nCREATE OR REPLACE TABLE CCDA_RESULTS (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n  VALUE        STRING,\n  UNIT         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\nCREATE OR REPLACE TABLE CCDA_PROBLEMS (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  STOP_RAW     STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  STOP_ISO     TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\nCREATE OR REPLACE TABLE CCDA_PROCEDURES (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  STOP_RAW     STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  STOP_ISO     TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\nCREATE OR REPLACE TABLE CCDA_ENCOUNTERS (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  STOP_RAW     STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  STOP_ISO     TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\n\nCREATE OR REPLACE TABLE CCDA_IMMUNIZATIONS (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\nCREATE OR REPLACE TABLE CCDA_FUNCTIONAL_STATUS (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n  VALUE        STRING,\n  UNIT         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\nCREATE OR REPLACE TABLE CCDA_ALLERGIES (\n  FILE_NAME              STRING,\n  START_RAW              STRING,\n  STOP_RAW               STRING,\n  START_ISO              TIMESTAMP_NTZ,\n  STOP_ISO               TIMESTAMP_NTZ,\n  SUBSTANCE_DESC         STRING,\n  SUBSTANCE_CODE_SYSTEM  STRING,\n  SUBSTANCE_CODE         STRING,\n  REACTION_DESC          STRING,\n  REACTION_CODE_SYSTEM   STRING,\n  REACTION_CODE          STRING,\n  SEVERITY               STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\nCREATE OR REPLACE TABLE CCDA_PLAN_OF_CARE (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  STOP_RAW     STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  STOP_ISO     TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\nCREATE OR REPLACE TABLE CCDA_SOCIAL_HISTORY (\n  FILE_NAME    STRING,\n  START_RAW    STRING,\n  STOP_RAW     STRING,\n  START_ISO    TIMESTAMP_NTZ,\n  STOP_ISO     TIMESTAMP_NTZ,\n  DESCRIPTION  STRING,\n  CODE_SYSTEM  STRING,\n  CODE         STRING,\n  VALUE        STRING,\n  UNIT         STRING,\n\n  PATIENT_ID       STRING,\n  DOCUMENT_ID      STRING,\n  PATIENT_IDS_ALL  VARIANT,\n  SOURCE_SYSTEM    STRING,\n  RECORD_TYPE      STRING\n);\n\n\n\nCREATE OR REPLACE TABLE CCDA_INGEST_MANIFEST (\n  FILE_NAME                 STRING,\n  STATUS                    STRING,\n  REASON                    STRING,\n  COUNT_MEDICATIONS         NUMBER,\n  COUNT_VITALS              NUMBER,\n  COUNT_RESULTS             NUMBER,\n  COUNT_PROBLEMS            NUMBER,\n  COUNT_PROCEDURES          NUMBER,\n  COUNT_ENCOUNTERS          NUMBER,\n  COUNT_IMMUNIZATIONS       NUMBER,\n  COUNT_FUNCTIONAL_STATUS   NUMBER,\n  COUNT_ALLERGIES           NUMBER,\n  COUNT_PLAN_OF_CARE        NUMBER,\n  COUNT_SOCIAL_HISTORY      NUMBER,\n  PROCESSED_AT              TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n\n  -- Optional if each CCDA file maps to one patient (common):\n  PATIENT_ID                STRING,\n  DOCUMENT_ID               STRING\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac7754af-e65c-416d-ae31-438fbdeb592f",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": "SHOW TABLES IN CCDA_FINAL_ASSIGNMENT.CCDA;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e91a60f-b425-4a87-8967-c3efec098679",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "\n# Step 5 (Complete): Create a reusable CCDA parser package in the Notebook filesystem\n\nfrom pathlib import Path\n\npkg_dir = Path(\"ccda_parser\")\npkg_dir.mkdir(exist_ok=True)\n\n# --------------------------\n# __init__.py\n# --------------------------\n(pkg_dir / \"__init__.py\").write_text(\n    '''\"\"\"\nReusable C-CDA Parser\n\nParses CCDA XML (urn:hl7-org:v3) into tidy pandas DataFrames for Medications,\nDiagnostic Results, Problems, Procedures, Encounters, Vital Signs, Immunizations,\nand Functional Status.\n\"\"\"\n__version__ = \"0.1.0\"\n''',\n    encoding=\"utf-8\"\n)\n\n# --------------------------\n# parser.py — core utilities + extractors\n# --------------------------\nparser_py = r'''\nimport os\nimport xml.etree.ElementTree as ET\nfrom datetime import datetime, timezone, timedelta\nimport pandas as pd\n\n\n# HL7 namespaces\nns = {\"cda\": \"urn:hl7-org:v3\", \"sdtc\": \"urn:hl7-org:sdtc\"}\n\n\n# Configurable default timezone offset (e.g., +0530)\nDEFAULT_TZ = os.getenv(\"CCDA_DEFAULT_TZ\", \"+0530\")\n\n\n# -------- Utilities --------\n\ndef parse_hl7_ts(ts: str):\n    \"\"\"\n    Convert HL7 TS 'YYYYMMDDHHMMSS[±ZZZZ|Z]?' to datetime (tz-aware if offset exists).\n    - If only 14 chars (YYYYMMDDHHMMSS), no embedded offset.\n    - If more than 14 chars, the remainder may be 'Z' or '±ZZZZ'.\n    \"\"\"\n    if not ts:\n        return None\n    base = ts[:14]\n    offset = ts[14:] if len(ts) > 14 else None\n    try:\n        dt = datetime.strptime(base, \"%Y%m%d%H%M%S\")\n    except Exception:\n        return None\n\n    # Apply embedded offset if present\n    if offset:\n        if offset.upper() == \"Z\":\n            return dt.replace(tzinfo=timezone.utc)\n        if offset[0] in \"+-\":\n            try:\n                hours = int(offset[1:3]); mins = int(offset[3:5])\n                delta = timedelta(hours=hours, minutes=mins)\n                if offset.startswith(\"-\"):\n                    delta = -delta\n                return dt.replace(tzinfo=timezone(delta))\n            except Exception:\n                # Fall through to default offset if malformed\n                pass\n    # No embedded offset: return naive for now\n    return dt\n\n\ndef to_iso(ts: str, tz_offset: str = DEFAULT_TZ) -> str:\n    \"\"\"\n    Convert HL7 TS to ISO-8601 string.\n    - If TS has embedded offset, use it.\n    - Else apply configurable default tz_offset (e.g., '+0530').\n    \"\"\"\n    if not ts:\n        return \"\"\n    dt = parse_hl7_ts(ts)\n    if not dt:\n        return \"\"\n\n    # If no tzinfo and we want a default offset, apply it\n    if dt.tzinfo is None and tz_offset:\n        try:\n            hours = int(tz_offset[1:3]); mins = int(tz_offset[3:5])\n            delta = timedelta(hours=hours, minutes=mins)\n            if tz_offset.startswith(\"-\"):\n                delta = -delta\n            dt = dt.replace(tzinfo=timezone(delta))\n        except Exception:\n            # If tz_offset is malformed, keep naive\n            pass\n\n    return dt.isoformat()\n\n\ndef _gettext(el):\n    return (el.text or \"\").strip() if el is not None else \"\"\n\n\ndef validate_ccda_xml(text: str):\n    try:\n        root = ET.fromstring(text)\n    except Exception as e:\n        return False, f\"XML parse failed: {e}\"\n    if not root.tag.endswith(\"ClinicalDocument\"):\n        return False, \"Root element is not ClinicalDocument.\"\n    return True, \"OK\"\n\n\ndef discover_sections(root):\n    sections = []\n    for sec in root.findall(\".//cda:structuredBody/cda:component/cda:section\", ns):\n        title = _gettext(sec.find(\"cda:title\", ns))\n        code_el = sec.find(\"cda:code\", ns)\n        sec_code = code_el.get(\"code\") if code_el is not None else None\n        sec_code_system = code_el.get(\"codeSystem\") if code_el is not None else None\n        sections.append({\"title\": title, \"code\": sec_code, \"codeSystem\": sec_code_system, \"el\": sec})\n    return sections\n\n\n# ==== Helpers for narrative parsing (put near other utilities) ====\n\ndef _all_text(el):\n    if el is None:\n        return \"\"\n    return \"\".join(el.itertext()).strip()\n\ndef _split_code_and_system(text):\n    t = (text or \"\").strip()\n    if not t:\n        return \"\", \"\"\n    parts = t.split()\n    if len(parts) >= 2 and parts[0].startswith(\"http\"):\n        return parts[0], parts[-1]\n    return \"\", t\n\n\ndef _parse_table_rows_from_section(sec):\n    \"\"\"\n    Parse the first XHTML <table> under <cda:text>. Returns:\n    (headers_lc: list[str], rows: list[list[str]]).\n    Handles both namespaced and un-namespaced narrative tables.\n    \"\"\"\n    text_el = sec.find(\"./cda:text\", ns)\n    if text_el is None:\n        return [], []\n\n    # Try namespaced <table> first, then non-namespaced fallback\n    tables = text_el.findall(\".//cda:table\", ns)\n    if not tables:\n        tables = text_el.findall(\".//table\")\n\n    if not tables:\n        return [], []\n\n    table = tables[0]\n\n    # --- Headers ---\n    headers = []\n    thead = table.find(\"./cda:thead\", ns)\n    if thead is None:\n        thead = table.find(\"./thead\")\n    if thead is not None:\n        tr = thead.find(\"./cda:tr\", ns) or thead.find(\"./tr\")\n        if tr is not None:\n            ths = tr.findall(\"./cda:th\", ns)\n            if not ths:\n                ths = tr.findall(\"./th\")\n            headers = [\"\".join(th.itertext()).strip().lower() for th in ths]\n\n    # --- Body rows ---\n    body_rows = []\n    tbody = table.find(\"./cda:tbody\", ns) or table.find(\"./tbody\")\n    if tbody is not None:\n        trs = tbody.findall(\"./cda:tr\", ns)\n        if not trs:\n            trs = tbody.findall(\"./tr\")\n        for tr in trs:\n            tds = tr.findall(\"./cda:td\", ns)\n            if not tds:\n                tds = tr.findall(\"./td\")\n            cells = [\"\".join(td.itertext()).strip() for td in tds]\n            if cells and any(c.strip() for c in cells):\n                body_rows.append(cells)\n    else:\n        # No <tbody>, read all <tr> directly\n        trs = table.findall(\"./cda:tr\", ns)\n        if not trs:\n            trs = table.findall(\"./tr\")\n        # If no explicit headers, use first row as header\n        if not headers and trs:\n            first_tds = trs[0].findall(\"./cda:td\", ns) or trs[0].findall(\"./td\")\n            headers = [\"\".join(td.itertext()).strip().lower() for td in first_tds]\n            trs = trs[1:]\n        for tr in trs:\n            tds = tr.findall(\"./cda:td\", ns) or tr.findall(\"./td\")\n            cells = [\"\".join(td.itertext()).strip() for td in tds]\n            if cells and any(c.strip() for c in cells):\n                body_rows.append(cells)\n\n    return headers, body_rows\n\n\ndef _col_index(headers, name_variants):\n    \"\"\"\n    Find column index by matching any variant (case-insensitive).\n    name_variants: iterable of possible header names like [\"start\", \"start date\"].\n    \"\"\"\n    hlc = [h.strip().lower() for h in headers]\n    for nv in name_variants:\n        nv_l = nv.strip().lower()\n        if nv_l in hlc:\n            return hlc.index(nv_l)\n    return None\\\n\n\ndef get_start_stop(eff_el):\n    \"\"\"\n    Read start/stop from <effectiveTime> supporting:\n      - <effectiveTime value=\"...\"/>\n      - <effectiveTime><low value=\"...\"/><high value=\"...\"/></effectiveTime>\n    Returns (start_raw, stop_raw)\n    \"\"\"\n    if eff_el is None:\n        return (\"\", \"\")\n    start = eff_el.attrib.get(\"value\", \"\")\n    low = eff_el.find(\"cda:low\", ns)\n    high = eff_el.find(\"cda:high\", ns)\n    if not start and low is not None:\n        start = low.attrib.get(\"value\", \"\")\n    stop = high.attrib.get(\"value\", \"\") if high is not None else \"\"\n    return (start, stop)\n\n\n# Extend to_iso to handle ISO strings with timezone (from narrative tables)\ndef to_iso(ts: str) -> str:\n    \"\"\"Return ISO 8601 string or '' if ts invalid.\"\"\"\n    if not ts:\n        return \"\"\n    # Try HL7 compact TS first\n    dt = parse_hl7_ts(ts)\n    if dt:\n        return dt.isoformat()\n    # Try Python ISO parser (supports ±HH:MM)\n    try:\n        # Remove timezone for Silver NTZ consistency\n        from datetime import datetime\n        dt2 = datetime.fromisoformat(ts)\n        return dt2.replace(tzinfo=None).isoformat()\n    except Exception:\n        return \"\"\n\n\n# -------- Extractors --------\n\n\n# --- Patient / Document header helpers (add to parser.py utilities) ---\nimport json\nimport hashlib\n\ndef extract_patient_identifiers(root: ET.Element) -> dict:\n    \"\"\"\n    Extract patient identifiers from CCDA header.\n    Returns: {'patient_id': <str>, 'patient_ids_all': <json-string>}\n    Strategy:\n      - Prefer an <id> with @extension (e.g., MRN) and @assigningAuthorityName if present.\n      - Else first <id> with @extension.\n      - Else fall back to @root or a deterministic hash surrogate.\n    \"\"\"\n    ns = {\"cda\": \"urn:hl7-org:v3\"}\n    ids = root.findall('.//cda:recordTarget/cda:patientRole/cda:id', ns)\n\n    all_ids = []\n    for id_node in ids:\n        all_ids.append({\n            \"root\": id_node.attrib.get(\"root\"),\n            \"extension\": id_node.attrib.get(\"extension\"),\n            \"assigningAuthorityName\": id_node.attrib.get(\"assigningAuthorityName\")\n        })\n\n    chosen = None\n    for item in all_ids:\n        if item.get(\"extension\") and item.get(\"assigningAuthorityName\"):\n            chosen = item[\"extension\"]\n            break\n    if not chosen:\n        for item in all_ids:\n            if item.get(\"extension\"):\n                chosen = item[\"extension\"]\n                break\n\n    if not chosen:\n        # if no extension, try root; else surrogate from header bytes\n        chosen = (all_ids[0].get(\"root\") if all_ids else None)\n    if not chosen:\n        sample = ET.tostring(root, encoding=\"utf-8\", method=\"xml\")[:1024]\n        chosen = hashlib.md5(sample).hexdigest()\n\n    return {\n        \"patient_id\": chosen,\n        \"patient_ids_all\": json.dumps(all_ids, ensure_ascii=False)\n    }\n\ndef extract_document_id(root: ET.Element) -> str:\n    \"\"\"\n    Extract ClinicalDocument/id as a stable document identifier for lineage.\n    Prefer @extension; fallback to @root; else hash surrogate.\n    \"\"\"\n    ns = {\"cda\": \"urn:hl7-org:v3\"}\n    doc_id = root.find('./cda:id', ns)\n    if doc_id is not None:\n        ext = doc_id.attrib.get('extension')\n        if ext:\n            return ext\n        root_oid = doc_id.attrib.get('root')\n        if root_oid:\n            return root_oid\n    sample = ET.tostring(root, encoding=\"utf-8\", method=\"xml\")[:1024]\n    return hashlib.md5(sample).hexdigest()\n\n\ndef extract_medications(sections):\n    \"\"\"\n    Returns DataFrame columns:\n    file_name (to be added upstream), start_raw, stop_raw, start_iso, stop_iso,\n    description, code_system, code\n    \"\"\"\n    rows = []\n    for s in sections:\n        if s[\"title\"].lower().startswith(\"medication\"):\n            sec = s[\"el\"]\n            for entry in sec.findall(\".//cda:entry\", ns):\n                sa = entry.find(\".//cda:substanceAdministration\", ns)\n                if sa is None:\n                    continue\n                start = stop = \"\"\n                low = sa.find(\".//cda:low\", ns)\n                high = sa.find(\".//cda:high\", ns)\n                if low is not None:  start = low.get(\"value\",\"\")\n                if high is not None: stop  = high.get(\"value\",\"\")\n                desc, code_system, code_val = \"\", \"\", \"\"\n                prod_code = sa.find(\".//cda:consumable//cda:manufacturedProduct//cda:manufacturedMaterial//cda:code\", ns)\n                if prod_code is not None:\n                    desc = prod_code.get(\"displayName\",\"\") or _gettext(prod_code.find(\"cda:originalText\", ns))\n                    code_system = prod_code.get(\"codeSystemName\",\"\") or prod_code.get(\"codeSystem\",\"\")\n                    code_val = prod_code.get(\"code\",\"\")\n                else:\n                    name_el = sa.find(\".//cda:consumable//cda:manufacturedProduct//cda:manufacturedMaterial//cda:name\", ns)\n                    desc = _gettext(name_el)\n                rows.append({\n                    \"start_raw\": start, \"stop_raw\": stop,\n                    \"start_iso\": to_iso(start), \"stop_iso\": to_iso(stop),\n                    \"description\": desc, \"code_system\": code_system, \"code\": code_val\n                })\n    return pd.DataFrame(rows)\n\n\ndef extract_results(sections):\n    \"\"\"Diagnostic Results: start_raw/start_iso, description, LOINC code, value, unit\"\"\"\n    rows = []\n    for s in sections:\n        if \"result\" in (s[\"title\"] or \"\").lower():\n            sec = s[\"el\"]\n            for obs in sec.findall(\".//cda:observation\", ns):\n                code = obs.find(\"cda:code\", ns)\n                desc  = code.get(\"displayName\", \"\") if code is not None else \"\"\n                loinc = code.get(\"code\", \"\")        if code is not None else \"\"\n                eff = obs.find(\"cda:effectiveTime\", ns)\n                start_raw, stop_raw = get_start_stop(eff)\n                val_el = obs.find(\"cda:value\", ns)\n                value = val_el.get(\"value\", \"\") if val_el is not None else \"\"\n                unit  = val_el.get(\"unit\", \"\")  if val_el is not None else \"\"\n                rows.append({\n                    \"start_raw\": start_raw,\n                    \"start_iso\": to_iso(start_raw),\n                    \"description\": desc,\n                    \"code_system\": \"LOINC\",\n                    \"code\": loinc,\n                    \"value\": value,\n                    \"unit\": unit\n                })\n    return pd.DataFrame(rows)\n\ndef extract_problems(sections):\n    \"\"\"Problems: start/stop raw+iso, description, code_system (SNOMED), code\"\"\"\n    rows = []\n    for s in sections:\n        if \"problem\" in s[\"title\"].lower():\n            sec = s[\"el\"]\n            for obs in sec.findall(\".//cda:observation\", ns):\n                start = stop = \"\"\n                eff = obs.find(\"cda:effectiveTime\", ns)\n                if eff is not None:\n                    low = eff.find(\"cda:low\", ns); high = eff.find(\"cda:high\", ns)\n                    start = low.get(\"value\",\"\") if low is not None else \"\"\n                    stop  = high.get(\"value\",\"\") if high is not None else \"\"\n                val_code = obs.find(\"cda:value\", ns)\n                desc = val_code.get(\"displayName\",\"\") if val_code is not None else \"\"\n                code_val = val_code.get(\"code\",\"\") if val_code is not None else \"\"\n                code_system = val_code.get(\"codeSystemName\",\"\") if val_code is not None else \"\"\n                rows.append({\n                    \"start_raw\": start, \"stop_raw\": stop,\n                    \"start_iso\": to_iso(start), \"stop_iso\": to_iso(stop),\n                    \"description\": desc, \"code_system\": code_system, \"code\": code_val\n                })\n    return pd.DataFrame(rows)\n\n\ndef extract_procedures(sections):\n    \"\"\"Procedures/Surgeries: start/stop raw+iso, description, code_system, code\"\"\"\n    rows = []\n    for s in sections:\n        title = (s.get(\"title\") or \"\").lower()\n        if (\"procedure\" in title) or (\"surger\" in title):\n            sec = s[\"el\"]\n            for proc in sec.findall(\".//cda:procedure\", ns):\n                # Effective time: support value attribute & low/high children\n                eff = proc.find(\"cda:effectiveTime\", ns)\n                start_raw, stop_raw = get_start_stop(eff)\n\n                # Procedure code\n                code_el = proc.find(\"cda:code\", ns)\n                desc = code_el.get(\"displayName\", \"\") if code_el is not None else \"\"\n                if not desc and code_el is not None:\n                    desc = _gettext(code_el.find(\"cda:originalText\", ns))\n                code_val    = code_el.get(\"code\", \"\")          if code_el is not None else \"\"\n                code_system = code_el.get(\"codeSystemName\", \"\") if code_el is not None else \"\"\n\n                rows.append({\n                    \"start_raw\": start_raw,\n                    \"stop_raw\":  stop_raw,\n                    \"start_iso\": to_iso(start_raw),\n                    \"stop_iso\":  to_iso(stop_raw),\n                    \"description\": desc,\n                    \"code_system\": code_system,\n                    \"code\": code_val\n                })\n    return pd.DataFrame(rows)\n\ndef extract_encounters(sections):\n    \"\"\"Encounters: start/stop raw+iso, description, code_system, code\"\"\"\n    rows = []\n    for s in sections:\n        if \"encounter\" in s[\"title\"].lower():\n            sec = s[\"el\"]\n            for enc in sec.findall(\".//cda:encounter\", ns):\n                start = stop = \"\"\n                eff = enc.find(\"cda:effectiveTime\", ns)\n                if eff is not None:\n                    low = eff.find(\"cda:low\", ns); high = eff.find(\"cda:high\", ns)\n                    start = low.get(\"value\",\"\") if low is not None else \"\"\n                    stop  = high.get(\"value\",\"\") if high is not None else \"\"\n                code_el = enc.find(\"cda:code\", ns)\n                desc = code_el.get(\"displayName\",\"\") if code_el is not None else \"\"\n                code_val = code_el.get(\"code\",\"\") if code_el is not None else \"\"\n                code_system = code_el.get(\"codeSystemName\",\"\") if code_el is not None else \"\"\n                rows.append({\n                    \"start_raw\": start, \"stop_raw\": stop,\n                    \"start_iso\": to_iso(start), \"stop_iso\": to_iso(stop),\n                    \"description\": desc, \"code_system\": code_system, \"code\": code_val\n                })\n    return pd.DataFrame(rows)\n\n\ndef extract_vitals(sections):\n    \"\"\"Vitals: start_raw/start_iso, description, LOINC code, value, unit\"\"\"\n    rows = []\n    for s in sections:\n        if \"vital\" in (s[\"title\"] or \"\").lower():\n            sec = s[\"el\"]\n            for obs in sec.findall(\".//cda:observation\", ns):\n                code_el = obs.find(\"cda:code\", ns)\n                desc = code_el.get(\"displayName\", \"\") if code_el is not None else \"\"\n                loinc = code_el.get(\"code\", \"\") if code_el is not None else \"\"\n                eff = obs.find(\"cda:effectiveTime\", ns)\n                start_raw, stop_raw = get_start_stop(eff)\n                val_el = obs.find(\"cda:value\", ns)\n                value = val_el.get(\"value\", \"\") if val_el is not None else \"\"\n                unit  = val_el.get(\"unit\", \"\")  if val_el is not None else \"\"\n                rows.append({\n                    \"start_raw\": start_raw,\n                    \"start_iso\": to_iso(start_raw),\n                    \"description\": desc,\n                    \"code_system\": \"LOINC\",\n                    \"code\": loinc,\n                    \"value\": value,\n                    \"unit\": unit\n                })\n    return pd.DataFrame(rows)\n\n\ndef extract_immunizations(sections):\n    \"\"\"Immunizations: start_raw/start_iso, description, code_system (CVX), code\"\"\"\n    rows = []\n    for s in sections:\n        if \"immunization\" in (s[\"title\"] or \"\").lower():\n            sec = s[\"el\"]\n            for sa in sec.findall(\".//cda:substanceAdministration\", ns):\n                eff = sa.find(\"cda:effectiveTime\", ns)\n                start_raw, stop_raw = get_start_stop(eff)\n                prod_code = sa.find(\".//cda:consumable//cda:manufacturedProduct//cda:manufacturedMaterial//cda:code\", ns)\n                desc = prod_code.get(\"displayName\", \"\") if prod_code is not None else \"\"\n                code_val = prod_code.get(\"code\", \"\")     if prod_code is not None else \"\"\n                code_system = prod_code.get(\"codeSystemName\", \"\") if prod_code is not None else \"\"\n                rows.append({\n                    \"start_raw\": start_raw,\n                    \"start_iso\": to_iso(start_raw),\n                    \"description\": desc,\n                    \"code_system\": code_system,\n                    \"code\": code_val\n                })\n    return pd.DataFrame(rows)\n\n\ndef extract_functional_status(sections):\n    \"\"\"Functional Status: start_raw/start_iso, description, LOINC code, value, unit\"\"\"\n    rows = []\n    for s in sections:\n        if \"functional\" in (s[\"title\"] or \"\").lower():\n            sec = s[\"el\"]\n            for obs in sec.findall(\".//cda:observation\", ns):\n                code_el = obs.find(\"cda:code\", ns)\n                desc = code_el.get(\"displayName\", \"\") if code_el is not None else \"\"\n                code_val = code_el.get(\"code\", \"\")    if code_el is not None else \"\"\n                val_el = obs.find(\"cda:value\", ns)\n                value = val_el.get(\"value\", \"\") if val_el is not None else \"\"\n                unit  = val_el.get(\"unit\", \"\")  if val_el is not None else \"\"\n                eff = obs.find(\"cda:effectiveTime\", ns)\n                start_raw, stop_raw = get_start_stop(eff)\n                rows.append({\n                    \"start_raw\": start_raw,\n                    \"start_iso\": to_iso(start_raw),\n                    \"description\": desc,\n                    \"code_system\": \"LOINC\",\n                    \"code\": code_val,\n                    \"value\": value,\n                    \"unit\": unit\n                })\n    return pd.DataFrame(rows)\n\n\n\n# --- Allergies / Adverse Events ---\n\ndef extract_allergies(sections):\n    \"\"\"\n    Allergies & Adverse Reactions:\n    Returns columns:\n    start_raw, stop_raw, start_iso, stop_iso,\n    substance_desc, substance_code_system, substance_code,\n    reaction_desc, reaction_code_system, reaction_code, severity\n    \"\"\"\n    import pandas as pd\n    rows = []\n\n    def _emit_row(start, stop, desc, code_text):\n        cs, cd = _split_code_and_system(code_text)\n        rows.append({\n            \"start_raw\": start or \"\",\n            \"stop_raw\":  stop or \"\",\n            \"start_iso\": to_iso(start or \"\"),\n            \"stop_iso\":  to_iso(stop or \"\"),\n            \"substance_desc\": desc or \"\",\n            \"substance_code_system\": cs or \"\",\n            \"substance_code\": cd or \"\",\n            # Narrative tables rarely include reaction/severity explicitly\n            \"reaction_desc\": \"\",\n            \"reaction_code_system\": \"\",\n            \"reaction_code\": \"\",\n            \"severity\": \"\"\n        })\n\n    for s in sections:\n        title = (s.get(\"title\") or \"\").lower()\n        code  = (s.get(\"code\") or \"\").strip()\n        # match by title or LOINC section code\n        if (\"allerg\" in title) or (code in {\"48765-2\", \"29299-5\"}):\n            sec = s[\"el\"]\n            # Structured entries (preferred)\n            for entry in sec.findall(\"./cda:entry\", ns):\n                node = entry.find(\"./cda:act\", ns) or entry.find(\"./cda:observation\", ns)\n                if node is None:\n                    continue\n                # effectiveTime\n                start = stop = \"\"\n                eff = node.find(\"./cda:effectiveTime\", ns)\n                if eff is not None:\n                    low = eff.find(\"cda:low\", ns); high = eff.find(\"cda:high\", ns)\n                    start = low.get(\"value\",\"\") if low is not None else (eff.get(\"value\",\"\") or \"\")\n                    stop  = high.get(\"value\",\"\") if high is not None else \"\"\n                # substance from participant\n                desc = code_text = \"\"\n                pe = node.find(\".//cda:participant/cda:participantRole/cda:playingEntity\", ns)\n                if pe is not None:\n                    pcode = pe.find(\"./cda:code\", ns)\n                    if pcode is not None:\n                        desc = pcode.get(\"displayName\",\"\") or _gettext(pcode.find(\"cda:originalText\", ns))\n                        code_text = pcode.get(\"code\",\"\")\n                    if not desc:\n                        desc = _gettext(pe.find(\"./cda:name\", ns))\n                _emit_row(start, stop, desc, code_text)\n\n            # Narrative fallback if no <entry>\n            if not rows:\n                headers, table_rows = _parse_table_rows_from_section(sec)\n                if headers and table_rows:\n                    i_start = _col_index(headers, [\"start\", \"start date\", \"start time\"])\n                    i_stop  = _col_index(headers, [\"stop\", \"stop date\", \"stop time\", \"end\"])\n                    i_desc  = _col_index(headers, [\"description\", \"substance\", \"allergen\"])\n                    i_code  = _col_index(headers, [\"code\", \"code / system\", \"code system\"])\n                    for cells in table_rows:\n                        start = cells[i_start] if i_start is not None and i_start < len(cells) else \"\"\n                        stop  = cells[i_stop]  if i_stop  is not None and i_stop  < len(cells) else \"\"\n                        desc  = cells[i_desc]  if i_desc  is not None and i_desc  < len(cells) else \"\"\n                        code_text = cells[i_code] if i_code is not None and i_code < len(cells) else \"\"\n                        # In your sample: 'http://snomed.info/sct 419199007'\n                        _emit_row(start, stop, desc, code_text)\n\n    return pd.DataFrame(rows)\n\n\n# --- Plan of Care ---\n\ndef extract_plan_of_care(sections):\n    \"\"\"\n    Plan of Care entries: start/stop, description, code_system, code.\n    Supports structured <entry><act|observation> and narrative table/list fallback.\n    \"\"\"\n    import pandas as pd\n    rows = []\n\n    def _emit_row(start, stop, desc, code_text):\n        cs, cd = _split_code_and_system(code_text)\n        rows.append({\n            \"start_raw\": start or \"\",\n            \"stop_raw\":  stop or \"\",\n            \"start_iso\": to_iso(start or \"\"),\n            \"stop_iso\":  to_iso(stop or \"\"),\n            \"description\": desc or \"\",\n            \"code_system\": cs or \"\",\n            \"code\": cd or \"\"\n        })\n\n    for s in sections:\n        title = (s.get(\"title\") or \"\").lower()\n        if \"plan of care\" in title or \"care plan\" in title or title.strip() == \"plan\":\n            sec = s[\"el\"]\n\n            # Structured entries\n            for entry in sec.findall(\"./cda:entry\", ns):\n                node = entry.find(\"./cda:act\", ns) or entry.find(\"./cda:observation\", ns)\n                if node is None:\n                    continue\n\n                # Effective time: support @value and low/high\n                eff = node.find(\"./cda:effectiveTime\", ns)\n                start_raw, stop_raw = get_start_stop(eff)\n\n                code_el = node.find(\"./cda:code\", ns)\n                desc = code_el.get(\"displayName\", \"\") if code_el is not None else \"\"\n                if not desc and code_el is not None:\n                    desc = _gettext(code_el.find(\"cda:originalText\", ns))\n                code_text = code_el.get(\"code\", \"\") if code_el is not None else \"\"\n\n                _emit_row(start_raw, stop_raw, desc, code_text)\n\n            # Narrative fallback (table or list)\n            if not rows:\n                headers, table_rows = _parse_table_rows_from_section(sec)\n                if headers and table_rows:\n                    i_start = _col_index(headers, [\"start\", \"start date\", \"start time\"])\n                    i_stop  = _col_index(headers, [\"stop\", \"stop date\", \"stop time\", \"end\"])\n                    i_desc  = _col_index(headers, [\"description\", \"plan\", \"care plan\", \"activity\"])\n                    i_code  = _col_index(headers, [\"code\", \"code / system\", \"code system\"])\n                    for cells in table_rows:\n                        start = cells[i_start] if i_start is not None and i_start < len(cells) else \"\"\n                        stop  = cells[i_stop]  if i_stop  is not None and i_stop  < len(cells) else \"\"\n                        desc  = cells[i_desc]  if i_desc  is not None and i_desc  < len(cells) else \"\"\n                        code_text = cells[i_code] if i_code is not None and i_code < len(cells) else \"\"\n                        _emit_row(start, stop, desc, code_text)\n                else:\n                    text_el = sec.find(\"./cda:text\", ns)\n                    if text_el is not None:\n                        for item in text_el.findall(\".//item\"):\n                            _emit_row(\"\", \"\", _all_text(item), \"\")\n\n    return pd.DataFrame(rows)\n\n# --- Social History ---\n\ndef extract_social_history(sections):\n    \"\"\"\n    Social History observations: start/stop, description, code_system, code, value, unit.\n    Handles structured <entry><observation> and narrative tables/lists.\n    \"\"\"\n    import pandas as pd\n    rows = []\n\n    def _emit_row(start, stop, desc, code_text, value, unit):\n        cs, cd = _split_code_and_system(code_text)\n        rows.append({\n            \"start_raw\": start or \"\",\n            \"stop_raw\":  stop or \"\",\n            \"start_iso\": to_iso(start or \"\"),\n            \"stop_iso\":  to_iso(stop or \"\"),\n            \"description\": desc or \"\",\n            \"code_system\": cs or \"\",\n            \"code\": cd or \"\",\n            \"value\": value or \"\",\n            \"unit\": unit or \"\"\n        })\n\n    for s in sections:\n        title = (s.get(\"title\") or \"\").lower()\n        if \"social\" in title:\n            sec = s[\"el\"]\n\n            # Structured entries\n            for entry in sec.findall(\"./cda:entry\", ns):\n                obs = entry.find(\"./cda:observation\", ns)\n                if obs is None:\n                    continue\n\n                # Effective time: support @value and low/high\n                eff = obs.find(\"./cda:effectiveTime\", ns)\n                start_raw, stop_raw = get_start_stop(eff)\n\n                code_el = obs.find(\"./cda:code\", ns)\n                desc = code_el.get(\"displayName\", \"\") if code_el is not None else \"\"\n                if not desc and code_el is not None:\n                    desc = _gettext(code_el.find(\"cda:originalText\", ns))\n                code_text = code_el.get(\"code\", \"\") if code_el is not None else \"\"\n\n                val_el = obs.find(\"./cda:value\", ns)\n                value = unit = \"\"\n                if val_el is not None:\n                    # Use displayName/code/value text as available\n                    value = val_el.get(\"displayName\", \"\") or val_el.get(\"code\", \"\") or (val_el.text or \"\").strip()\n                    unit  = val_el.get(\"unit\", \"\") or \"\"\n\n                _emit_row(start_raw, stop_raw, desc, code_text, value, unit)\n\n            # Narrative fallback (table or list)\n            if not rows:\n                headers, table_rows = _parse_table_rows_from_section(sec)\n                if headers and table_rows:\n                    i_start = _col_index(headers, [\"start\", \"start date\", \"start time\"])\n                    i_stop  = _col_index(headers, [\"stop\", \"stop date\", \"stop time\", \"end\"])\n                    i_desc  = _col_index(headers, [\"description\", \"item\", \"topic\"])\n                    i_code  = _col_index(headers, [\"code\", \"code / system\", \"code system\"])\n                    i_value = _col_index(headers, [\"value\", \"result\", \"answer\"])\n                    i_unit  = _col_index(headers, [\"unit\"])\n                    for cells in table_rows:\n                        start = cells[i_start] if i_start is not None and i_start < len(cells) else \"\"\n                        stop  = cells[i_stop]  if i_stop  is not None and i_stop  < len(cells) else \"\"\n                        desc  = cells[i_desc]  if i_desc  is not None and i_desc  < len(cells) else \"\"\n                        code_text = cells[i_code] if i_code is not None and i_code < len(cells) else \"\"\n                        value = cells[i_value] if i_value is not None and i_value < len(cells) else \"\"\n                        unit  = cells[i_unit]  if i_unit  is not None and i_unit  < len(cells) else \"\"\n                        _emit_row(start, stop, desc, code_text, value, unit)\n                else:\n                    # Narrative list fallback\n                    text_el = sec.find(\"./cda:text\", ns)\n                    if text_el is not None:\n                        for item in text_el.findall(\".//item\"):\n                            _emit_row(\"\", \"\", _all_text(item), \"\", \"\", \"\")\n\n    return pd.DataFrame(rows)\n\n'''\n(pkg_dir / \"parser.py\").write_text(parser_py, encoding=\"utf-8\")\n\n# --------------------------\n# parse_text.py — entrypoint to parse raw XML text\n# --------------------------\nparse_text_py = r'''\nimport xml.etree.ElementTree as ET\nimport pandas as pd\nfrom .parser import (\n    validate_ccda_xml, discover_sections,\n    extract_medications, extract_results, extract_problems,\n    extract_procedures, extract_encounters, extract_vitals,\n    extract_immunizations, extract_functional_status,\n    extract_allergies, extract_plan_of_care, extract_social_history,\n    extract_patient_identifiers, extract_document_id\n)\n\n\n\ndef parse_ccda_text(xml_text: str):\n    \"\"\"\n    Entry point used by the pipeline:\n      - Validates the CCDA XML text\n      - Discovers sections\n      - Runs extractors to build pandas DataFrames per domain\n      - Returns (dfs_dict, meta_dict)\n\n    Returns:\n        dfs: dict[str, pd.DataFrame]\n        meta: dict with keys:\n              - status: \"parsed\" | \"rejected\"\n              - reason: str\n              - patient_id: str\n              - patient_ids_all: json string\n              - document_id: str\n    \"\"\"\n    if not isinstance(xml_text, str) or not xml_text.strip():\n        return ({}, {\"status\": \"rejected\", \"reason\": \"empty input\"})\n\n    ok, reason = validate_ccda_xml(xml_text)\n    if not ok:\n        return ({}, {\"status\": \"rejected\", \"reason\": reason})\n\n    # Parse XML and discover sections\n    root = ET.fromstring(xml_text)\n    sections = discover_sections(root)\n\n    # Run extractors (each returns a pandas DataFrame)\n    dfs = {\n        \"medications\":        extract_medications(sections),\n        \"vitals\":             extract_vitals(sections),\n        \"results\":            extract_results(sections),\n        \"problems\":           extract_problems(sections),\n        \"procedures\":         extract_procedures(sections),\n        \"encounters\":         extract_encounters(sections),\n        \"immunizations\":      extract_immunizations(sections),\n        \"functional_status\":  extract_functional_status(sections),\n        \"allergies\":          extract_allergies(sections),\n        \"plan_of_care\":       extract_plan_of_care(sections),\n        \"social_history\":     extract_social_history(sections),\n    }\n\n    # Patient/document metadata for lineage\n    pi   = extract_patient_identifiers(root)   # {'patient_id', 'patient_ids_all'}\n    docid = extract_document_id(root)\n\n    meta = {\n        \"status\": \"parsed\",\n        \"reason\": \"OK\",\n        \"patient_id\":      pi.get(\"patient_id\"),\n        \"patient_ids_all\": pi.get(\"patient_ids_all\"),\n        \"document_id\":     docid,\n    }\n\n    return dfs, meta\n\n\n\n'''\n(pkg_dir / \"parse_text.py\").write_text(parse_text_py, encoding=\"utf-8\")\n\nprint(\"✅ Parser package created at:\", pkg_dir.resolve())\n\nfrom ccda_parser import __version__",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9dbb3ce0-1ffe-434f-8329-c21b8908cd93",
   "metadata": {
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": "\n# # plan_of_care_parser.py\n# import xml.etree.ElementTree as ET\n# from datetime import datetime, timezone, timedelta\n# import pandas as pd\n\n# # HL7 namespaces\n# ns = {\"cda\": \"urn:hl7-org:v3\", \"sdtc\": \"urn:hl7-org:sdtc\"}\n\n# # ---- Minimal utilities ----\n# def _gettext(el):\n#     return (el.text or \"\").strip() if el is not None else \"\"\n\n# def _all_text(el):\n#     if el is None:\n#         return \"\"\n#     return \"\".join(el.itertext()).strip()\n\n# def _parse_table_rows_from_section(sec):\n#     \"\"\"Parse the first XHTML <table> under <cda:text>. Return (headers_lc, rows).\"\"\"\n#     text_el = sec.find(\"./cda:text\", ns)\n#     if text_el is None:\n#         return [], []\n\n#     tables = text_el.findall(\".//cda:table\", ns)\n#     if not tables:\n#         tables = text_el.findall(\".//table\")\n#     if not tables:\n#         return [], []\n#     table = tables[0]\n\n#     # headers\n#     headers = []\n#     thead = table.find(\"./cda:thead\", ns) or table.find(\"./thead\")\n#     if thead is not None:\n#         tr = thead.find(\"./cda:tr\", ns) or thead.find(\"./tr\")\n#         if tr is not None:\n#             ths = tr.findall(\"./cda:th\", ns)\n#             if not ths:\n#                 ths = tr.findall(\"./th\")\n#             headers = [\"\".join(th.itertext()).strip().lower() for th in ths]\n\n#     # body rows\n#     body_rows = []\n#     tbody = table.find(\"./cda:tbody\", ns) or table.find(\"./tbody\")\n#     if tbody is not None:\n#         trs = tbody.findall(\"./cda:tr\", ns) or tbody.findall(\"./tr\")\n#         for tr in trs:\n#             tds = tr.findall(\"./cda:td\", ns) or tr.findall(\"./td\")\n#             cells = [\"\".join(td.itertext()).strip() for td in tds]\n#             if cells and any(c.strip() for c in cells):\n#                 body_rows.append(cells)\n#     else:\n#         trs = table.findall(\"./cda:tr\", ns) or table.findall(\"./tr\")\n#         if trs:\n#             first_tds = trs[0].findall(\"./cda:td\", ns) or trs[0].findall(\"./td\")\n#             if not headers:\n#                 headers = [\"\".join(td.itertext()).strip().lower() for td in first_tds]\n#                 trs = trs[1:]\n#         for tr in trs:\n#             tds = tr.findall(\"./cda:td\", ns) or tr.findall(\"./td\")\n#             cells = [\"\".join(td.itertext()).strip() for td in tds]\n#             if cells and any(c.strip() for c in cells):\n#                 body_rows.append(cells)\n\n#     return headers, body_rows\n\n# def _col_index(headers, name_variants):\n#     hlc = [h.strip().lower() for h in headers]\n#     for nv in name_variants:\n#         nv_l = nv.strip().lower()\n#         if nv_l in hlc:\n#             return hlc.index(nv_l)\n#     return None\n\n# def parse_hl7_ts(ts: str):\n#     \"\"\"\n#     Convert HL7 TS 'YYYYMMDDHHMMSS[±ZZZZ]?' to datetime (tz-aware if offset exists).\n#     \"\"\"\n#     if not ts:\n#         return None\n#     base = ts[:14]\n#     offset = ts[14:] if len(ts) > 14 else None\n#     try:\n#         dt = datetime.strptime(base, \"%Y%m%d%H%M%S\")\n#     except Exception:\n#         return None\n#     if offset:\n#         if offset.upper() == \"Z\":\n#             return dt.replace(tzinfo=timezone.utc)\n#         if offset[0] in \"+-\":\n#             try:\n#                 hours = int(offset[1:3]); mins = int(offset[3:5])\n#                 delta = timedelta(hours=hours, minutes=mins)\n#                 if offset.startswith(\"-\"):\n#                     delta = -delta\n#                 return dt.replace(tzinfo=timezone(delta))\n#             except Exception:\n#                 pass\n#     return dt  # naive\n\n# def to_iso(ts: str, default_tz=\"+0530\") -> str:\n#     \"\"\"\n#     Convert HL7 TS to ISO-8601 string.\n#     If TS has embedded offset, use it; else apply default_tz (e.g., '+0530').\n#     Also accept already ISO strings.\n#     \"\"\"\n#     if not ts:\n#         return \"\"\n#     # HL7 compact first\n#     dt = parse_hl7_ts(ts)\n#     if dt:\n#         if dt.tzinfo is None and default_tz:\n#             try:\n#                 hours = int(default_tz[1:3]); mins = int(default_tz[3:5])\n#                 delta = timedelta(hours=hours, minutes=mins)\n#                 if default_tz.startswith(\"-\"):\n#                     delta = -delta\n#                 dt = dt.replace(tzinfo=timezone(delta))\n#             except Exception:\n#                 pass\n#         return dt.isoformat()\n#     # try Python ISO (±HH:MM)\n#     try:\n#         dt2 = datetime.fromisoformat(ts)\n#         return dt2.isoformat()\n#     except Exception:\n#         return \"\"\n\n# def get_start_stop(eff_el):\n#     \"\"\"\n#     Read start/stop from <effectiveTime> supporting:\n#     - <effectiveTime value=\"...\"/>\n#     - <effectiveTime><low value=\"...\"/><high value=\"...\"/></effectiveTime>\n#     Returns (start_raw, stop_raw)\n#     \"\"\"\n#     if eff_el is None:\n#         return (\"\", \"\")\n#     start = eff_el.attrib.get(\"value\", \"\")\n#     low = eff_el.find(\"cda:low\", ns)\n#     high = eff_el.find(\"cda:high\", ns)\n#     if not start and low is not None:\n#         start = low.attrib.get(\"value\", \"\")\n#     stop = high.attrib.get(\"value\", \"\") if high is not None else \"\"\n#     return (start, stop)\n\n# def _split_code_and_system(text):\n#     \"\"\"\n#     For narrative cells that sometimes combine system+code as:\n#       'http://snomed.info/sct 419199007'\n#     Return (system_url, code_value) or (\"\", text) if only a code.\n#     \"\"\"\n#     t = (text or \"\").strip()\n#     if not t:\n#         return \"\", \"\"\n#     parts = t.split()\n#     if len(parts) >= 2 and parts[0].startswith(\"http\"):\n#         return parts[0], parts[-1]\n#     return \"\", t\n\n# # ---- Core: Plan of Care only ----\n# def parse_plan_of_care(text: str, *, default_tz=\"+0530\") -> pd.DataFrame:\n#     \"\"\"\n#     Parse ONLY the Plan of Treatment/Plan of Care section from a CCDA XML string.\n\n#     Returns a DataFrame with columns:\n#       start_raw, stop_raw, start_iso, stop_iso, description, code_system, code\n\n#     It does not read or return any other sections.\n#     \"\"\"\n#     # Validate XML\n#     try:\n#         root = ET.fromstring(text)\n#     except Exception as e:\n#         raise ValueError(f\"XML parse failed: {e}\")\n\n#     if not root.tag.endswith(\"ClinicalDocument\"):\n#         raise ValueError(\"Root element is not ClinicalDocument.\")\n\n#     # Discover sections (both common paths to be safe)\n#     sections = []\n#     for sec in root.findall(\".//cda:structuredBody/cda:component/cda:section\", ns):\n#         title = _gettext(sec.find(\"cda:title\", ns))\n#         code_el = sec.find(\"cda:code\", ns)\n#         sec_code = code_el.get(\"code\") if code_el is not None else None\n#         sections.append({\"title\": title, \"code\": sec_code, \"el\": sec})\n#     for sec in root.findall(\".//cda:component/cda:section\", ns):\n#         title = _gettext(sec.find(\"cda:title\", ns))\n#         code_el = sec.find(\"cda:code\", ns)\n#         sec_code = code_el.get(\"code\") if code_el is not None else None\n#         sections.append({\"title\": title, \"code\": sec_code, \"el\": sec})\n\n#     rows = []\n\n#     def _emit_row(start, stop, desc, code_text):\n#         cs, cd = _split_code_and_system(code_text)\n#         rows.append({\n#             \"start_raw\": start or \"\",\n#             \"stop_raw\": stop or \"\",\n#             \"start_iso\": to_iso(start or \"\", default_tz),\n#             \"stop_iso\": to_iso(stop or \"\", default_tz),\n#             \"description\": (desc or \"\").strip(),\n#             \"code_system\": cs or \"\",\n#             \"code\": cd or \"\"\n#         })\n\n#     # Identify candidate Plan-of-Care sections (title, code 18776-5, templateId)\n#     poc_secs = []\n#     for s in sections:\n#         title = (s.get(\"title\") or \"\").lower()\n#         code = (s.get(\"code\") or \"\").strip()\n#         sec_el = s[\"el\"]\n#         template_ids = [tid.attrib.get(\"root\") for tid in sec_el.findall(\"./cda:templateId\", ns)]\n#         if (\n#             \"plan of care\" in title\n#             or \"plan of treatment\" in title\n#             or \"care plan\" in title\n#             or title.strip() == \"plan\"\n#             or code == \"18776-5\"  # LOINC Plan of care note\n#             or \"2.16.840.1.113883.10.20.22.2.10\" in template_ids  # Plan of Treatment Section (V2)\n#         ):\n#             poc_secs.append(sec_el)\n\n#     for sec in poc_secs:\n#         # Structured entries: act, procedure, observation (and nested organizer/component)\n#         for entry in sec.findall(\"./cda:entry\", ns):\n#             node = (entry.find(\"./cda:act\", ns)\n#                     or entry.find(\"./cda:procedure\", ns)\n#                     or entry.find(\"./cda:observation\", ns))\n#             if node is None:\n#                 org = entry.find(\"./cda:organizer\", ns)\n#                 if org is not None:\n#                     for comp in org.findall(\"./cda:component\", ns):\n#                         node2 = (comp.find(\"./cda:act\", ns)\n#                                  or comp.find(\"./cda:procedure\", ns)\n#                                  or comp.find(\"./cda:observation\", ns))\n#                         if node2 is None:\n#                             continue\n#                         eff = node2.find(\"./cda:effectiveTime\", ns)\n#                         start_raw, stop_raw = get_start_stop(eff)\n#                         code_el = node2.find(\"./cda:code\", ns)\n#                         desc = code_el.get(\"displayName\", \"\") if code_el is not None else \"\"\n#                         if not desc and code_el is not None:\n#                             desc = _gettext(code_el.find(\"cda:originalText\", ns))\n#                         code_text = code_el.get(\"code\", \"\") if code_el is not None else \"\"\n#                         _emit_row(start_raw, stop_raw, desc, code_text)\n#                     continue\n#             if node is None:\n#                 continue\n\n#             eff = node.find(\"./cda:effectiveTime\", ns)\n#             start_raw, stop_raw = get_start_stop(eff)\n#             code_el = node.find(\"./cda:code\", ns)\n#             desc = code_el.get(\"displayName\", \"\") if code_el is not None else \"\"\n#             if not desc and code_el is not None:\n#                 desc = _gettext(code_el.find(\"cda:originalText\", ns))\n#             code_text = code_el.get(\"code\", \"\") if code_el is not None else \"\"\n#             _emit_row(start_raw, stop_raw, desc, code_text)\n\n#         # Narrative fallback (Date/time, Goal, Instructions, Description)\n#         if not rows:\n#             headers, table_rows = _parse_table_rows_from_section(sec)\n#             if headers and table_rows:\n#                 i_start = _col_index(headers, [\"start\", \"start date\", \"start time\", \"date/time\", \"date\", \"time\"])\n#                 i_stop  = _col_index(headers, [\"stop\", \"stop date\", \"stop time\", \"end\"])\n#                 i_goal  = _col_index(headers, [\"goal\", \"care goal\"])\n#                 i_instr = _col_index(headers, [\"instructions\", \"plan\", \"care plan\", \"activity\", \"intervention\"])\n#                 i_desc  = _col_index(headers, [\"description\"])\n#                 for cells in table_rows:\n#                     start = cells[i_start] if i_start is not None and i_start < len(cells) else \"\"\n#                     stop  = cells[i_stop]  if i_stop  is not None and i_stop  < len(cells) else \"\"\n#                     goal  = cells[i_goal]  if i_goal  is not None and i_goal  < len(cells) else \"\"\n#                     instr = cells[i_instr] if i_instr is not None and i_instr < len(cells) else \"\"\n#                     desc  = cells[i_desc]  if i_desc  is not None and i_desc  < len(cells) else \"\"\n#                     text = (goal + (\"; \" if goal and instr else \"\") + instr) or desc\n#                     _emit_row(start, stop, text, \"\")\n#             else:\n#                 text_el = sec.find(\"./cda:text\", ns)\n#                 if text_el is not None:\n#                     for item in text_el.findall(\".//item\"):\n#                         _emit_row(\"\", \"\", _all_text(item), \"\")\n\n#     return pd.DataFrame(rows)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "24059610-5288-4c45-b594-278d01306b3f",
   "metadata": {
    "language": "python",
    "name": "cell35"
   },
   "outputs": [],
   "source": "\n# # -- Read Bronze → Parse Plan of Care (only) → Load Silver & Manifest --\n\n# from snowflake.snowpark.context import get_active_session\n# session = get_active_session()\n# assert session is not None, \"No active Snowpark session.\"\n\n# # 1) Read ALL raw CCDA docs from Bronze\n# df = session.sql(\"\"\"\n#     SELECT FILE_NAME, TO_VARCHAR(DOC) AS XML_TEXT\n#     FROM FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE\n# \"\"\")\n# rows = df.collect()\n# assert rows, \"Bronze has no rows.\"\n\n# import pandas as pd\n# import xml.etree.ElementTree as ET\n# import json\n\n# from snowflake.connector.pandas_tools import write_pandas\n\n# # 👉 IMPORTANT: import the Plan-of-Care-only parser\n# # from plan_of_care_parser import parse_plan_of_care   # if in module\n# # If you defined parse_plan_of_care inline, ensure it's in scope.\n\n# DB = \"FINAL_ASSIGNMENT\"\n# SCHEMA = \"CCDA\"\n\n# # --- Only Plan of Care domain/table ---\n# DOMAIN_TO_TABLE = {\n#     \"plan_of_care\": \"CCDA_PLAN_OF_CARE\",\n# }\n\n# ISO_TIME_COLS = {\"start_iso\", \"stop_iso\"}\n\n# # ---------------- Helper: minimal CCDA meta ----------------\n# ns = {\"cda\": \"urn:hl7-org:v3\"}\n\n# def get_ccda_meta(xml_text: str) -> dict:\n#     \"\"\"\n#     Extract minimal meta without running the full parser:\n#       - patient_id: first recordTarget/patientRole/id/@extension (or @root if no extension)\n#       - document_id: ClinicalDocument/id/@extension (or @root)\n#       - patient_ids_all: JSON array of {root, extension} for patientRole/id[]\n#     \"\"\"\n#     meta = {\"status\": \"parsed\", \"reason\": \"\"}\n#     try:\n#         root = ET.fromstring(xml_text)\n#     except Exception as e:\n#         meta[\"status\"] = \"rejected\"\n#         meta[\"reason\"] = f\"XML parse failed: {e}\"\n#         return meta\n\n#     # document_id\n#     doc_id_el = root.find(\"./cda:id\", ns)\n#     if doc_id_el is not None:\n#         meta[\"document_id\"] = doc_id_el.attrib.get(\"extension\") or doc_id_el.attrib.get(\"root\")\n#     else:\n#         meta[\"document_id\"] = None\n\n#     # patient ids\n#     pid_els = root.findall(\".//cda:recordTarget/cda:patientRole/cda:id\", ns)\n#     ids_all = []\n#     for el in pid_els:\n#         ids_all.append({\n#             \"root\": el.attrib.get(\"root\"),\n#             \"extension\": el.attrib.get(\"extension\")\n#         })\n#     meta[\"patient_ids_all\"] = json.dumps(ids_all, ensure_ascii=False)\n#     # first usable patient_id\n#     if ids_all:\n#         meta[\"patient_id\"] = ids_all[0].get(\"extension\") or ids_all[0].get(\"root\")\n#     else:\n#         meta[\"patient_id\"] = None\n\n#     return meta\n\n# # -------- Normalize (unchanged; works for single domain) --------\n# def normalize_domain_dfs(dfs: dict, file_name: str, meta: dict) -> dict:\n#     \"\"\"\n#     Add FILE_NAME + context (patient_id, document_id, patient_ids_all),\n#     convert *_ISO to datetimes, and uppercase columns.\n#     Idempotent: does not create duplicate column names.\n#     \"\"\"\n#     out = {}\n#     patient_id = meta.get(\"patient_id\")\n#     document_id = meta.get(\"document_id\")\n#     patient_ids_all = meta.get(\"patient_ids_all\")  # JSON string\n\n#     for domain, pdf in dfs.items():\n#         if pdf is None or pdf.empty:\n#             out[domain] = pdf\n#             continue\n\n#         # --- Add columns only if missing ---\n#         def ensure(col_name: str, value):\n#             if col_name not in pdf.columns:\n#                 pdf[col_name] = value\n\n#         ensure(\"FILE_NAME\", file_name)\n#         ensure(\"PATIENT_ID\", patient_id)\n#         ensure(\"DOCUMENT_ID\", document_id)\n#         ensure(\"PATIENT_IDS_ALL\", patient_ids_all)\n#         ensure(\"SOURCE_SYSTEM\", \"CCDA\")\n#         ensure(\"RECORD_TYPE\", domain)\n\n#         # --- Convert ISO columns safely ---\n#         for col in list(pdf.columns):\n#             base = col.lower()\n#             if base in ISO_TIME_COLS:\n#                 pdf[col] = pd.to_datetime(pdf[col], errors=\"coerce\")\n\n#         # --- Uppercase column names ONCE ---\n#         upper_cols = [c.upper() for c in pdf.columns]\n\n#         # --- Ensure uniqueness after uppercasing ---\n#         seen = set()\n#         final_cols = []\n#         for c in upper_cols:\n#             if c in seen:\n#                 continue  # drop exact duplicate name\n#             seen.add(c)\n#             final_cols.append(c)\n\n#         # Rebuild the DataFrame with unique, uppercased columns, keeping first occurrence\n#         pdf = pdf.loc[:, pdf.columns[:len(final_cols)]]\n#         pdf.columns = final_cols\n#         out[domain] = pdf\n\n#     return out\n\n# def write_df(table_name: str, pdf: pd.DataFrame) -> int:\n#     \"\"\"Write a pandas DataFrame to a Silver table via write_pandas.\"\"\"\n#     if pdf is None or pdf.empty:\n#         return 0\n#     success, nchunks, nrows, _ = write_pandas(\n#         conn=session.connection,\n#         df=pdf,\n#         table_name=table_name,\n#         database=DB,\n#         schema=SCHEMA,\n#         quote_identifiers=False,  # assumes Silver columns are unquoted UPPERCASE\n#         overwrite=False\n#     )\n#     if not success:\n#         raise RuntimeError(f\"write_pandas failed for {DB}.{SCHEMA}.{table_name}\")\n#     return nrows\n\n# def log_manifest_row(file_name: str, status: str, reason: str, counts: dict, meta: dict = None):\n#     \"\"\"Log one manifest row; other domain counts default to 0.\"\"\"\n#     manifest_row = {\n#         \"FILE_NAME\": file_name,\n#         \"STATUS\": status,\n#         \"REASON\": reason or \"\",\n#         # other domains = 0; only plan_of_care populated\n#         \"COUNT_MEDICATIONS\":        0,\n#         \"COUNT_VITALS\":             0,\n#         \"COUNT_RESULTS\":            0,\n#         \"COUNT_PROBLEMS\":           0,\n#         \"COUNT_PROCEDURES\":         0,\n#         \"COUNT_ENCOUNTERS\":         0,\n#         \"COUNT_IMMUNIZATIONS\":      0,\n#         \"COUNT_FUNCTIONAL_STATUS\":  0,\n#         \"COUNT_ALLERGIES\":          0,\n#         \"COUNT_PLAN_OF_CARE\":       counts.get(\"plan_of_care\", 0),\n#         \"COUNT_SOCIAL_HISTORY\":     0,\n#     }\n#     if meta:\n#         manifest_row[\"PATIENT_ID\"]  = meta.get(\"patient_id\")\n#         manifest_row[\"DOCUMENT_ID\"] = meta.get(\"document_id\")\n\n#     manifest_pdf = pd.DataFrame([manifest_row])\n\n#     ok, _, _, _ = write_pandas(\n#         conn=session.connection,\n#         df=manifest_pdf,\n#         table_name=\"CCDA_INGEST_MANIFEST\",\n#         database=DB,\n#         schema=SCHEMA,\n#         quote_identifiers=False\n#     )\n#     if not ok:\n#         raise RuntimeError(\"Failed to write manifest row\")\n\n# # (Idempotent) remove existing Plan of Care rows for the file (and optional document_id)\n# def delete_plan_of_care_rows_for_file(file_name: str, document_id: str = None):\n#     safe_file = (file_name or \"\").replace(\"'\", \"''\")\n#     safe_doc  = (document_id or \"\").replace(\"'\", \"''\")\n#     table = DOMAIN_TO_TABLE[\"plan_of_care\"]\n#     if document_id:\n#         session.sql(\n#             f\"DELETE FROM {DB}.{SCHEMA}.{table} WHERE FILE_NAME = '{safe_file}' AND DOCUMENT_ID = '{safe_doc}'\"\n#         ).collect()\n#     else:\n#         session.sql(\n#             f\"DELETE FROM {DB}.{SCHEMA}.{table} WHERE FILE_NAME = '{safe_file}'\"\n#         ).collect()\n\n# # ---------- Process ALL rows (Plan of Care only) ----------\n# grand_counts = {\"plan_of_care\": 0}\n# processed = 0\n# failed = 0\n\n# DEFAULT_TZ = \"+0530\"  # for to_iso conversion inside parse_plan_of_care\n\n# for r in rows:\n#     FILE_NAME = r[\"FILE_NAME\"]\n#     xml_text  = r[\"XML_TEXT\"]\n\n#     print(f\"\\n=== Processing (Plan of Care): {FILE_NAME} ===\")\n\n#     # Minimal meta (no full parser)\n#     meta = get_ccda_meta(xml_text)\n\n#     try:\n#         if meta.get(\"status\") != \"parsed\":\n#             # rejected (bad XML, etc.)\n#             log_manifest_row(FILE_NAME, status=\"rejected\", reason=meta.get(\"reason\",\"\"), counts={}, meta=meta)\n#             print(f\"Rejected: {FILE_NAME} | Reason: {meta.get('reason','')}\")\n#             failed += 1\n#             continue\n\n#         # delete only from CCDA_PLAN_OF_CARE\n#         delete_plan_of_care_rows_for_file(FILE_NAME, meta.get(\"document_id\"))\n\n#         # --- Parse ONLY Plan of Care ---\n#         poc_df = parse_plan_of_care(xml_text, default_tz=DEFAULT_TZ)\n\n#         # --- Normalize with patient/document context ---\n#         dfs_norm = normalize_domain_dfs({\"plan_of_care\": poc_df}, FILE_NAME, meta)\n\n#         # --- Write Plan of Care to Silver ---\n#         count_poc = write_df(DOMAIN_TO_TABLE[\"plan_of_care\"], dfs_norm[\"plan_of_care\"])\n#         grand_counts[\"plan_of_care\"] += count_poc\n\n#         # --- Log success ---\n#         log_manifest_row(FILE_NAME, status=\"parsed\", reason=\"OK\", counts={\"plan_of_care\": count_poc}, meta=meta)\n#         print(f\"Loaded Plan of Care: {FILE_NAME} | Rows: {count_poc}\")\n#         processed += 1\n\n#     except Exception as e:\n#         log_manifest_row(FILE_NAME, status=\"failed\", reason=str(e), counts={}, meta=meta if meta else None)\n#         print(f\"Failed: {FILE_NAME} | Error: {e}\")\n#         failed += 1\n\n# print(\"\\n=== Summary (Plan of Care only) ===\")\n# print(f\"Processed: {processed} | Failed: {failed} | Total Plan of Care rows: {grand_counts['plan_of_care']}\")\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "80b5c5d3-dbc6-4daf-af00-93c2c9206cd8",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\n# Step 5 (Sanity tests): import package and optionally parse one local file\n\nfrom ccda_parser import __version__\nfrom ccda_parser.parse_text import parse_ccda_text\nfrom pathlib import Path\n\nprint(\"ccda_parser version:\", __version__)\n\n# Optional quick self-check: if you already ran GET and have a file in /tmp/ccda_xml, parse it\ncandidate_dir = Path(\"/tmp/ccda_xml\")\ncandidate_files = sorted(candidate_dir.glob(\"*.xml\"))\n# print(candidate_files)\nif candidate_files:\n    sample = candidate_files[0]\n    print(f\"[INFO] Parsing sample: {sample.name}\")\n    xml_text = sample.read_text(encoding=\"utf-8\", errors=\"ignore\")\n    dfs, meta = parse_ccda_text(xml_text)\n    print(\"Status:\", meta.get(\"status\"))\n    print(\"Section counts:\", meta.get(\"counts\"))\n    # Show a peek\n    for name, df in dfs.items():\n        print(f\"\\n{name} -> {len(df)} rows\")\n        display(df.head(3))\nelse:\n    print(\"[INFO] No local XML found in /tmp/ccda_xml yet. Run Step 6 (GET from stage) and re-run this test.\")\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc938720-aca7-4d13-90fc-bffeb8f9ab29",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": "\nSELECT\n  CURRENT_ACCOUNT()            AS account_locator,   -- legacy locator form\n  CURRENT_USER()               AS user_name,\n  CURRENT_ROLE()               AS role_name,\n  CURRENT_WAREHOUSE()          AS warehouse_name,\n  CURRENT_DATABASE()           AS database_name,\n  CURRENT_SCHEMA()             AS schema_name;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b3b8329-3724-4003-8b2d-75b85ca6db73",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "\n# from snowflake.snowpark import Session\n# # from snowflake.snowpark.context import get_active_session\n\n# # Fill these with your values (or use Notebook secrets/parameters)\n# connection_parameters = {\n#     \"account\":   \"HKC53319\",      # e.g., xy12345.ap-south-1\n#     \"user\":      \"SBAGUL077\",\n#     \"password\":  \"Winterspell#077\",             # consider keypair auth in prod\n#     \"role\":      \"SYSADMIN\",\n#     \"warehouse\": \"COMPUTE_WH\",\n#     \"database\":  \"CAPSTONE_DB\",\n#        \"schema\":    \"MEDALLION_SILVER\",\n# }\n\n# session = Session.builder.configs(connection_parameters).create()\n\n# # Optional sanity checks\n# session.sql(\"SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_DATABASE(), CURRENT_SCHEMA()\").collect()\n# print(\"[INFO] Snowpark session initialized.\")\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "09f78a95-b46c-4659-a7e6-fbb84caae91e",
   "metadata": {
    "language": "sql",
    "name": "cell11"
   },
   "outputs": [],
   "source": "select * from FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2595058e-2e27-4851-8c2d-17dc0d22ce88",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": "--NOT NEEDED MAYBE\n-- -- Use your database/schema\n-- USE DATABASE CAPSTONE_DB;\n-- USE SCHEMA MEDALLION_SILVER;\n\n-- -- Create the external stage (already fine)\n-- CREATE OR REPLACE STAGE ccda_xml_stage\n--   URL='s3://demosnowflakesanket/CCDA_Data/'\n--   STORAGE_INTEGRATION=S3_CCDA_INTEGRATION;\n\n-- -- Create a FILE FORMAT for XML (named constant)\n-- CREATE OR REPLACE FILE FORMAT xml_ccda_ff\n--   TYPE = XML\n--   COMPRESSION = AUTO;\n\n-- -- Verify the specific file is visible\n-- LIST @ccda_xml_stage PATTERN='.*Nancey580_Melissa844_McGlynn426_b26b56d5-928d-13c0-8b47-080d343d0878\\.xml$';\n\n-- -- Bronze table\n-- CREATE OR REPLACE TABLE ccda_bronze (\n--   file_name STRING,\n--   doc       VARIANT\n-- );\n\n-- -- Load the single XML into Bronze using the named file format\n-- COPY INTO ccda_bronze (file_name, doc)\n-- FROM (\n--   SELECT METADATA$FILENAME, $1\n--   FROM @ccda_xml_stage/Nancey580_Melissa844_McGlynn426_b26b56d5-928d-13c0-8b47-080d343d0878.xml\n--        (FILE_FORMAT => 'xml_ccda_ff')\n-- );\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e450b7ff-4272-4e38-ba07-dd876c8dec53",
   "metadata": {
    "language": "sql",
    "name": "cell17"
   },
   "outputs": [],
   "source": "DESC TABLE ccda_bronze;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0913ffac-d6fc-4480-9bde-aa24dd5d5337",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": "\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nsession.sql(\"USE DATABASE CAPSTONE_DB\").collect()\nsession.sql(\"USE SCHEMA MEDALLION_SILVER\").collect()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5276512f-e172-4d6f-a2b4-e671dd8a5dd9",
   "metadata": {
    "language": "sql",
    "name": "cell19"
   },
   "outputs": [],
   "source": "TRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_ALLERGIES;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_MEDICATIONS;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_VITALS;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_RESULTS;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_PROBLEMS;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_PROCEDURES;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_ENCOUNTERS;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_IMMUNIZATIONS;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_FUNCTIONAL_STATUS;\nTRUNCATE TABLE FINAL_ASSIGNMENT.CCDA.CCDA_INGEST_MANIFEST;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8908eebb-68fc-44ab-b753-185c5cdd609d",
   "metadata": {
    "language": "sql",
    "name": "cell32"
   },
   "outputs": [],
   "source": "\nCREATE OR REPLACE PROCEDURE CCDA.SP_PROCESS_CCDA_STREAM()\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.10'\nPACKAGES = ('snowflake-snowpark-python', 'pandas', 'snowflake-connector-python')\nHANDLER = 'run'\nAS\n$$\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.connector.pandas_tools import write_pandas\nfrom ccda_parser.parse_text import parse_ccda_text  # from your package\nimport pandas as pd\n\nDB = \"FINAL_ASSIGNMENT\"\nSCHEMA = \"CCDA\"\n\n# Domain → table mapping (same as your script)\nDOMAIN_TO_TABLE = {\n  \"medications\": \"CCDA_MEDICATIONS\",\n  \"vitals\": \"CCDA_VITALS\",\n  \"results\": \"CCDA_RESULTS\",\n  \"problems\": \"CCDA_PROBLEMS\",\n  \"procedures\": \"CCDA_PROCEDURES\",\n  \"encounters\": \"CCDA_ENCOUNTERS\",\n  \"immunizations\": \"CCDA_IMMUNIZATIONS\",\n  \"functional_status\": \"CCDA_FUNCTIONAL_STATUS\",\n  \"allergies\": \"CCDA_ALLERGIES\",\n  \"plan_of_care\": \"CCDA_PLAN_OF_CARE\",\n  \"social_history\": \"CCDA_SOCIAL_HISTORY\",\n}\n\nISO_TIME_COLS = {\"start_iso\", \"stop_iso\"}\n\ndef normalize_domain_dfs(dfs: dict, file_name: str, meta: dict) -> dict:\n    # (use your existing implementation; simplified here)\n    out = {}\n    patient_id = meta.get(\"patient_id\")\n    document_id = meta.get(\"document_id\")\n    patient_ids_all = meta.get(\"patient_ids_all\")\n    for domain, pdf in dfs.items():\n        if pdf is None or pdf.empty:\n            out[domain] = pdf\n            continue\n        # add context columns if missing\n        for col, val in [\n            (\"FILE_NAME\", file_name),\n            (\"PATIENT_ID\", patient_id),\n            (\"DOCUMENT_ID\", document_id),\n            (\"PATIENT_IDS_ALL\", patient_ids_all),\n            (\"SOURCE_SYSTEM\", \"CCDA\"),\n            (\"RECORD_TYPE\", domain),\n        ]:\n            if col not in pdf.columns:\n                pdf[col] = val\n        # convert *_ISO safely\n        for col in list(pdf.columns):\n            if col.lower() in ISO_TIME_COLS:\n                pdf[col] = pd.to_datetime(pdf[col], errors=\"coerce\")\n        # uppercase & dedupe column names (safer variant)\n        pdf.columns = pdf.columns.str.upper()\n        pdf = pdf.loc[:, ~pdf.columns.duplicated()]  # keep first occurrence\n        out[domain] = pdf\n    return out\n\ndef write_df(session, table_name: str, pdf: pd.DataFrame) -> int:\n    if pdf is None or pdf.empty:\n        return 0\n    success, nchunks, nrows, _ = write_pandas(\n        conn=session.connection,\n        df=pdf,\n        table_name=table_name,\n        database=DB,\n        schema=SCHEMA,\n        quote_identifiers=False,\n        overwrite=False\n    )\n    if not success:\n        raise RuntimeError(f\"write_pandas failed for {DB}.{SCHEMA}.{table_name}\")\n    return nrows\n\ndef log_manifest_row(session, file_name: str, status: str, reason: str, counts: dict, meta: dict = None):\n    row = {\n      \"FILE_NAME\": file_name, \"STATUS\": status, \"REASON\": reason or \"\",\n      \"COUNT_MEDICATIONS\": counts.get(\"medications\", 0),\n      \"COUNT_VITALS\": counts.get(\"vitals\", 0),\n      \"COUNT_RESULTS\": counts.get(\"results\", 0),\n      \"COUNT_PROBLEMS\": counts.get(\"problems\", 0),\n      \"COUNT_PROCEDURES\": counts.get(\"procedures\", 0),\n      \"COUNT_ENCOUNTERS\": counts.get(\"encounters\", 0),\n      \"COUNT_IMMUNIZATIONS\": counts.get(\"immunizations\", 0),\n      \"COUNT_FUNCTIONAL_STATUS\": counts.get(\"functional_status\", 0),\n      \"COUNT_ALLERGIES\": counts.get(\"allergies\", 0),\n      \"COUNT_PLAN_OF_CARE\": counts.get(\"plan_of_care\", 0),\n      \"COUNT_SOCIAL_HISTORY\": counts.get(\"social_history\", 0),\n    }\n    if meta:\n        row[\"PATIENT_ID\"]  = meta.get(\"patient_id\")\n        row[\"DOCUMENT_ID\"] = meta.get(\"document_id\")\n    mdf = pd.DataFrame([row])\n    ok, _, _, _ = write_pandas(\n        conn=session.connection,\n        df=mdf,\n        table_name=\"CCDA_INGEST_MANIFEST\",\n        database=DB,\n        schema=SCHEMA,\n        quote_identifiers=False\n    )\n    if not ok:\n        raise RuntimeError(\"Failed to write manifest row\")\n\ndef delete_existing_rows_for_file(session, file_name: str, document_id: str = None):\n    safe_file = (file_name or \"\").replace(\"'\", \"''\")\n    safe_doc  = (document_id or \"\").replace(\"'\", \"''\")\n    for table in DOMAIN_TO_TABLE.values():\n        if document_id:\n            session.sql(f\"DELETE FROM {DB}.{SCHEMA}.{table} WHERE FILE_NAME = '{safe_file}' AND DOCUMENT_ID = '{safe_doc}'\").collect()\n        else:\n            session.sql(f\"DELETE FROM {DB}.{SCHEMA}.{table} WHERE FILE_NAME = '{safe_file}'\").collect()\n\ndef run():\n    session = get_active_session()\n    assert session is not None, \"No active Snowpark session.\"\n\n    # Read only new rows from the STREAM (incremental)\n    df = session.sql(\"\"\"\n        SELECT FILE_NAME, TO_VARCHAR(DOC) AS XML_TEXT\n        FROM CCDA_BRONZE_STREAM\n    \"\"\")\n    rows = df.collect()\n    if not rows:\n        return \"No new rows in CCDA_BRONZE_STREAM.\"\n\n    processed, failed = 0, 0\n\n    for r in rows:\n        FILE_NAME = r[\"FILE_NAME\"]\n        XML_TEXT  = r[\"XML_TEXT\"]\n        try:\n            session.sql(\"BEGIN\").collect()\n            dfs, meta = parse_ccda_text(XML_TEXT, file_name=FILE_NAME)  # uses your parser\n            if meta.get(\"status\") != \"parsed\":\n                log_manifest_row(session, FILE_NAME, \"rejected\", meta.get(\"reason\",\"\"), {}, meta)\n                session.sql(\"COMMIT\").collect()\n                failed += 1\n                continue\n\n            # Optional idempotency: clear previous rows for this file+document\n            delete_existing_rows_for_file(session, FILE_NAME, meta.get(\"document_id\"))\n\n            dfs_norm = normalize_domain_dfs(dfs, FILE_NAME, meta)\n            counts = {}\n            for domain, table in DOMAIN_TO_TABLE.items():\n                counts[domain] = write_df(session, table, dfs_norm.get(domain))\n\n            log_manifest_row(session, FILE_NAME, \"parsed\", \"OK\", counts, meta)\n            session.sql(\"COMMIT\").collect()\n            processed += 1\n        except Exception as e:\n            session.sql(\"ROLLBACK\").collect()\n            # best-effort failure manifest\n            try:\n                log_manifest_row(session, FILE_NAME, \"failed\", str(e), {}, meta if 'meta' in locals() else None)\n            except Exception:\n                pass\n            failed += 1\n\n    return f\"Processed OK: {processed}, Failed/Rejected: {failed}\"\n$$;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2d349ec-f325-4191-810b-f574e5b113dd",
   "metadata": {
    "language": "sql",
    "name": "cell31"
   },
   "outputs": [],
   "source": "\n-- Driver task (runs every 30 days at midnight UTC)\nCREATE OR REPLACE TASK CCDA.TASK_PROCESS_CCDA_STREAM\n  WAREHOUSE = COMPUTE_WH\n  SCHEDULE = 'USING CRON 0 0 1 * * UTC'  -- At 00:00 UTC on the 1st of every month\nAS\nCALL CCDA.SP_PROCESS_CCDA_STREAM();\n\n-- Start the task\nALTER TASK CCDA.TASK_PROCESS_CCDA_STREAM RESUME;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "281797ff-89a5-43ec-9fbb-6d979f4de785",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\n# -- Read Bronze → Parse CCDA in Python → Load Silver & Manifest (Python cell)\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nassert session is not None, \"No active Snowpark session.\"\n\n# 1) Read ALL raw CCDA docs from Bronze\ndf = session.sql(\"\"\"\n    SELECT FILE_NAME, TO_VARCHAR(DOC) AS XML_TEXT\n    FROM CCDA_BRONZE\n\"\"\")\nrows = df.collect()\nassert rows, \"Bronze has no rows.\"\n\nimport pandas as pd\nfrom snowflake.connector.pandas_tools import write_pandas\nfrom ccda_parser.parse_text import parse_ccda_text\n\nDB = \"CCDA_FINAL_ASSIGNMENT\"\nSCHEMA = \"CCDA\"\n\n# Domain → Silver table mapping (UPPERCASE Snowflake tables)\nDOMAIN_TO_TABLE = {\n    \"medications\":        \"CCDA_MEDICATIONS\",\n    \"vitals\":             \"CCDA_VITALS\",\n    \"results\":            \"CCDA_RESULTS\",\n    \"problems\":           \"CCDA_PROBLEMS\",\n    \"procedures\":         \"CCDA_PROCEDURES\",\n    \"encounters\":         \"CCDA_ENCOUNTERS\",\n    \"immunizations\":      \"CCDA_IMMUNIZATIONS\",\n    \"functional_status\":  \"CCDA_FUNCTIONAL_STATUS\",\n    # NEW\n    \"allergies\":          \"CCDA_ALLERGIES\",\n    \"plan_of_care\":       \"CCDA_PLAN_OF_CARE\",\n    \"social_history\":     \"CCDA_SOCIAL_HISTORY\",\n}\n\n# Columns that should be parsed to datetime (ISO ones only)\nISO_TIME_COLS = {\"start_iso\", \"stop_iso\"}\n\n\n\nISO_TIME_COLS = {\"start_iso\", \"stop_iso\"}\n\ndef normalize_domain_dfs(dfs: dict, file_name: str, meta: dict) -> dict:\n    \"\"\"\n    Add FILE_NAME + context (patient_id, document_id, patient_ids_all),\n    convert *_ISO to datetimes, and uppercase columns.\n    Idempotent: does not create duplicate column names.\n    \"\"\"\n    out = {}\n    patient_id = meta.get(\"patient_id\")\n    document_id = meta.get(\"document_id\")\n    patient_ids_all = meta.get(\"patient_ids_all\")  # JSON string from parser\n\n    for domain, pdf in dfs.items():\n        if pdf is None or pdf.empty:\n            out[domain] = pdf\n            continue\n\n        # --- Add columns only if missing ---\n        def ensure(col_name: str, value):\n            if col_name not in pdf.columns:\n                pdf[col_name] = value\n\n        ensure(\"FILE_NAME\", file_name)\n        ensure(\"PATIENT_ID\", patient_id)\n        ensure(\"DOCUMENT_ID\", document_id)\n        ensure(\"PATIENT_IDS_ALL\", patient_ids_all)\n        ensure(\"SOURCE_SYSTEM\", \"CCDA\")\n        ensure(\"RECORD_TYPE\", domain)\n\n        # --- Convert ISO columns safely (case-insensitive match) ---\n        # If parser already uppercased, handle both cases\n        for col in list(pdf.columns):\n            base = col.lower()\n            if base in ISO_TIME_COLS:\n                pdf[col] = pd.to_datetime(pdf[col], errors=\"coerce\")\n\n        # --- Uppercase column names ONCE ---\n        upper_cols = [c.upper() for c in pdf.columns]\n\n        # --- Ensure uniqueness after uppercasing (avoid rare case like 'Patient_ID'/'PATIENT_ID') ---\n        seen = set()\n        final_cols = []\n        for c in upper_cols:\n            if c in seen:\n                # append a numeric suffix to keep write_pandas happy; but prefer to drop duplicates\n                # Here we drop exact duplicates by keeping the FIRST occurrence:\n                # skip duplicates entirely\n                continue\n            seen.add(c)\n            final_cols.append(c)\n\n        # Rebuild the DataFrame with unique, uppercased columns, keeping first occurrence of each\n        pdf = pdf.loc[:, pdf.columns[:len(final_cols)]]\n        pdf.columns = final_cols\n        out[domain] = pdf\n\n    return out\n\ndef write_df(table_name: str, pdf: pd.DataFrame) -> int:\n    \"\"\"Write a pandas DataFrame to a Silver table via write_pandas.\"\"\"\n    if pdf is None or pdf.empty:\n        return 0\n    success, nchunks, nrows, _ = write_pandas(\n        conn=session.connection,\n        df=pdf,\n        table_name=table_name,\n        database=DB,\n        schema=SCHEMA,\n        quote_identifiers=False,  # assumes Silver columns are unquoted UPPERCASE\n        overwrite=False\n    )\n    if not success:\n        raise RuntimeError(f\"write_pandas failed for {DB}.{SCHEMA}.{table_name}\")\n    return nrows\n\n\ndef log_manifest_row(file_name: str, status: str, reason: str, counts: dict, meta: dict = None):\n    \"\"\"Log one manifest row; optionally include patient/document context.\"\"\"\n    manifest_row = {\n        \"FILE_NAME\": file_name,\n        \"STATUS\": status,\n        \"REASON\": reason or \"\",\n        \"COUNT_MEDICATIONS\":        counts.get(\"medications\", 0),\n        \"COUNT_VITALS\":             counts.get(\"vitals\", 0),\n        \"COUNT_RESULTS\":            counts.get(\"results\", 0),\n        \"COUNT_PROBLEMS\":           counts.get(\"problems\", 0),\n        \"COUNT_PROCEDURES\":         counts.get(\"procedures\", 0),\n        \"COUNT_ENCOUNTERS\":         counts.get(\"encounters\", 0),\n        \"COUNT_IMMUNIZATIONS\":      counts.get(\"immunizations\", 0),\n        \"COUNT_FUNCTIONAL_STATUS\":  counts.get(\"functional_status\", 0),\n        \"COUNT_ALLERGIES\":          counts.get(\"allergies\", 0),\n        \"COUNT_PLAN_OF_CARE\":       counts.get(\"plan_of_care\", 0),\n        \"COUNT_SOCIAL_HISTORY\":     counts.get(\"social_history\", 0),\n    }\n    if meta:\n        manifest_row[\"PATIENT_ID\"]  = meta.get(\"patient_id\")\n        \n        manifest_row[\"DOCUMENT_ID\"] = meta.get(\"document_id\")\n\n    manifest_pdf = pd.DataFrame([manifest_row])\n\n    ok, _, _, _ = write_pandas(\n        conn=session.connection,\n        df=manifest_pdf,\n        table_name=\"CCDA_INGEST_MANIFEST\",\n        database=DB,\n        schema=SCHEMA,\n        quote_identifiers=False\n    )\n    if not ok:\n        raise RuntimeError(\"Failed to write manifest row\")\n\n# (Optional) make reruns idempotent: remove existing Silver rows for the file\ndef delete_existing_rows_for_file(file_name: str):\n    safe = (file_name or \"\").replace(\"'\", \"''\")\n    for table in DOMAIN_TO_TABLE.values():\n        session.sql(f\"DELETE FROM {DB}.{SCHEMA}.{table} WHERE FILE_NAME = '{safe}'\").collect()\n\n# ---------- Process ALL rows ----------\ngrand_counts = {k: 0 for k in DOMAIN_TO_TABLE.keys()}\nprocessed = 0\nfailed = 0\n\n\n\nfor r in rows:\n    FILE_NAME = r[\"FILE_NAME\"]\n    xml_text  = r[\"XML_TEXT\"]\n\n    print(f\"\\n=== Processing: {FILE_NAME} ===\")\n    delete_existing_rows_for_file(FILE_NAME)  # optional\n\n    try:\n        dfs, meta = parse_ccda_text(xml_text)\n\n        # Rejected parse → log and continue\n        if meta.get(\"status\") != \"parsed\":\n            log_manifest_row(FILE_NAME, status=\"rejected\", reason=meta.get(\"reason\",\"\"), counts={}, meta=meta)\n            print(f\"Rejected: {FILE_NAME} | Reason: {meta.get('reason','')}\")\n            failed += 1\n            continue\n\n        # Normalize with patient/document context\n        dfs_norm = normalize_domain_dfs(dfs, FILE_NAME, meta)\n\n        counts = {}\n        for domain, table in DOMAIN_TO_TABLE.items():\n            counts[domain] = write_df(table, dfs_norm.get(domain))\n\n        # Update totals\n        for domain in grand_counts:\n            grand_counts[domain] += counts.get(domain, 0)\n\n        # Log success including patient/doc\n        log_manifest_row(FILE_NAME, status=\"parsed\", reason=\"OK\", counts=counts, meta=meta)\n        print(f\"Parsed & loaded: {FILE_NAME} | Counts: {counts}\")\n        processed += 1\n\n    except Exception as e:\n        log_manifest_row(FILE_NAME, status=\"failed\", reason=str(e), counts={}, meta=meta if 'meta' in locals() else None)\n        print(f\"Failed: {FILE_NAME} | Error: {e}\")\n        failed += 1\n\ndef delete_existing_rows_for_file(file_name: str, document_id: str = None):\n    safe_file = (file_name or \"\").replace(\"'\", \"''\")\n    safe_doc  = (document_id or \"\").replace(\"'\", \"''\")\n    for table in DOMAIN_TO_TABLE.values():\n        if document_id:\n            session.sql(\n                f\"DELETE FROM {DB}.{SCHEMA}.{table} WHERE FILE_NAME = '{safe_file}' AND DOCUMENT_ID = '{safe_doc}'\"\n            ).collect()\n        else:\n            session.sql(\n                f\"DELETE FROM {DB}.{SCHEMA}.{table} WHERE FILE_NAME = '{safe_file}'\"\n            ).collect()\n\n\nprint(\"\\n=== Summary ===\")\nprint(f\"Processed OK: {processed}, Failed/Rejected: {failed}\")\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef8376d6-bea4-46f4-919a-47c5f664e8c6",
   "metadata": {
    "language": "sql",
    "name": "cell21"
   },
   "outputs": [],
   "source": "-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_ALLERGIES;\n\n-- SELECT count(1),FILE_NAME,\tSTART_RAW,\tSTOP_RAW,\tSTART_ISO,\tSTOP_ISO,\tDESCRIPTION,\tCODE_SYSTEM,\tCODE FROM FINAL_ASSIGNMENT.CCDA.CCDA_MEDICATIONS\n-- where file_name like '%James276_Bradtke547_052f9984-3e08-e364-872e-c2ed6284aaf6.xml'\n-- group by FILE_NAME,\tSTART_RAW,\tSTOP_RAW,\tSTART_ISO,\tSTOP_ISO,\tDESCRIPTION,\tCODE_SYSTEM,\tCODE\n-- order by 1 desc;\n-- select * FROM FINAL_ASSIGNMENT.CCDA.CCDA_MEDICATIONS;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_VITALS;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_RESULTS;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_PROBLEMS;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_PROCEDURES;\nSELECT * FROM CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_ENCOUNTERS;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_IMMUNIZATIONS;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_FUNCTIONAL_STATUS;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_INGEST_MANIFEST;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_PLAN_OF_CARE;\n-- SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_SOCIAL_HISTORY;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f2b2b52-137d-4616-bf44-025d83f06dca",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": "-- select * from CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE;\nCREATE OR REPLACE TABLE CCDA_FINAL_ASSIGNMENT.ccda.V_PATIENT_DEMOGRAPHICS AS\nWITH doc AS (\n  SELECT file_NAME AS DOC_ID, DOC AS x\n  FROM CCDA_FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE\n),\nrt AS (\n  SELECT DOC_ID, XMLGET(x, 'recordTarget') AS record_target\n  FROM doc\n),\npr AS (\n  SELECT DOC_ID, XMLGET(record_target, 'patientRole') AS patient_role\n  FROM rt\n),\np AS (\n  SELECT DOC_ID, XMLGET(patient_role, 'patient') AS patient\n  FROM pr\n),\naddr0 AS (\n  SELECT DOC_ID, XMLGET(patient_role, 'addr') AS addr\n  FROM pr\n),\ntele0 AS (\n  SELECT DOC_ID, XMLGET(patient_role, 'telecom') AS telecom\n  FROM pr\n),\nname0 AS (\n  SELECT DOC_ID, XMLGET(patient, 'name') AS name_el\n  FROM p\n)\nSELECT\n  d.DOC_ID,\n\n  /* Patient Contact Details */\n  COALESCE(GET(XMLGET(a.addr, 'streetAddressLine'), '$')::string, NULL) AS street_address_line,\n  COALESCE(GET(XMLGET(a.addr, 'city'), '$')::string, NULL)              AS city,\n  COALESCE(GET(XMLGET(a.addr, 'state'), '$')::string, NULL)             AS state,\n  COALESCE(GET(XMLGET(a.addr, 'postalCode'), '$')::string, NULL)        AS postal_code,\n  COALESCE(GET(XMLGET(a.addr, 'country'), '$')::string, NULL)           AS country,\n  REGEXP_REPLACE(GET(t.telecom, '@value')::string, '^tel:', '')         AS phone_raw,\n  REGEXP_REPLACE(GET(t.telecom, '@value')::string, '^mailto:', '')      AS email_raw,\n\n  /* Date of Birth */\n  TRY_TO_DATE(GET(XMLGET(p.patient, 'birthTime'), '@value')::string, 'YYYYMMDD') AS date_of_birth,\n\n  /* Gender, Race, Ethnicity */\n  GET(XMLGET(p.patient, 'administrativeGenderCode'), '@code')::string   AS gender_code,\n  GET(XMLGET(p.patient, 'raceCode'), '@code')::string                   AS race_code,\n  GET(XMLGET(p.patient, 'ethnicGroupCode'), '@code')::string            AS ethnicity_code,\n\n  /* Patient IDs */\n  GET(XMLGET(pr.patient_role, 'id'), '@root')::string                   AS patient_id_root,\n  GET(XMLGET(pr.patient_role, 'id'), '@extension')::string              AS patient_id_extension,\n\n  /* Language Communication */\n  GET(\n    XMLGET(XMLGET(p.patient, 'languageCommunication'), 'languageCode'),\n    '@code'\n  )::string AS language_code,\n\n  /* Optional Name */\n  GET(XMLGET(n.name_el, 'given'),  '$')::string                         AS given_name,\n  GET(XMLGET(n.name_el, 'family'), '$')::string                         AS family_name\n\nFROM doc d\nJOIN rt  r  ON r.DOC_ID  = d.DOC_ID\nJOIN pr  pr ON pr.DOC_ID = d.DOC_ID\nJOIN p   p  ON p.DOC_ID  = d.DOC_ID\nLEFT JOIN addr0 a ON a.DOC_ID = d.DOC_ID\nLEFT JOIN tele0 t ON t.DOC_ID = d.DOC_ID\nLEFT JOIN name0 n ON n.DOC_ID = d.DOC_ID;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6df3005d-8875-461d-a852-05a385f89a46",
   "metadata": {
    "language": "sql",
    "name": "cell33"
   },
   "outputs": [],
   "source": "-- select * from FINAL_ASSIGNMENT.CCDA.CCDA_BRONZE;\n\nSELECT * FROM CCDA_FINAL_ASSIGNMENT.CCDA.V_PATIENT_DEMOGRAPHICS",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "444eac91-582e-4013-a63c-6dffe96a4f3a",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": "SELECT * FROM FINAL_ASSIGNMENT.CCDA.CCDA_INGEST_MANIFEST;",
   "execution_count": null
  }
 ]
}